\chapter{CONCLUSION}
The overall focus of this dissertation has been on the application and evaluation of Bayesian regularization and model selection methods to obtain sparse estimation of linear and nonlinear time series models. A different model and application is provided in each chapter to illustrate the overall efficacy of considering Bayesian approaches for discovering the relevant temporal dynamics for the purpose of forecasting at multi-step horizons. Each chapter provides a novelty that contributes to the growing field of Bayesian time series analysis. 

In Chapter \ref{chap:temp}, different shrinkage priors are utilized to estimate a 2-regime smooth transition autoregressive model with a more flexible parametric representation than previously used. The use of the \textit{dirichlet} prior to select the delay parameter allows for composite transition variables to be estimated. Regime-specific tuning parameters in hierachical representations of global-local shrinkage priors ensure that regularization is regime-specific. The corresponding Appendix \ref{appendix1} contains detailed \textbf{R} code making these methods reproducible for future applications. Using deviations from daily maximum water temperature profiles, the ease of these methods in estimating smooth transition autoregressions with endogenous and exogenous lag effects is illustrated. Often smooth transition autoregressive models are applied to univariate time series, but the Bayesian methods discussed are able to perform selection on lag effects for input time series, such as deviations from maximum air temperature profiles.

The threshold autoregressive process is the limit of its smooth counterpart where the slope in the transition function approaches infinity. Often times in practice, the difficulty in estimation restricts consideration to threshold autoregressive models with at most 3 regimes. In Chapter \ref{chap:traffic}, the nonlinear threshold autoregressive process is restructured to a high dimensional linear regression model through limiting the thresholds to a finite set. This re-framed approach is only found in a handful of works but should become industry standard since the linear form nests all threshold autoregressive models with regimes less than the sample size. In this context, a fully Bayesian three step model building procedure is outlined to not only select the number of regimes but also perform within regime variable selection. Empirical results from a high dimensional simulation study in Appendix \ref{appendix3} are referenced to defend the choice of the horseshoe+ shrinkage prior. Using traffic occupancy data, the best subset TAR model outperforms seasonal profiles for 3 minute, 9 minute, and 15 minute forecasting horizons. Final TAR models are also used to produce density forecasts for the entire out-of-sample period. 

Chapter 4 focuses on subset selection of the classic autoregressive moving average model which has proven to be most popular in modeling and forecasting stationary time series. By considering subset selection methods, the more complicated multiplicative seasonal model can be estimated without knowing the period. From a frequentist viewpoint, penalized adaptive LASSO estimation has been used to yield consistent subset selection of these models. The adaptive elastic net is a natural extension from adaptive LASSO with a more flexible penalty. Previous works have used information criteria to select tuning parameters in these circumstances. Various cross-validation techniques are also appropriate alternatives to information criteria, even for time series data. For comparison, a Bayesian approach, that uses the Kullback-Leibler distance, searches for the best submodel with a posterior predictive distribution relatively close to the predictions from the full model. Within this method, there are multiple ways to identify the final model that do not require cross-validation. In simulation, potential pitfalls of adaptive lasso and adaptive elastic net are shown, highlighting the advantages of the Bayesian-based posterior predictive projection algorithm. Subset ARMA methods are applied to $\textrm{CO}_2$ data from two locations. Multiple measures of forecasting accuracy and bias assess the techniques for one-step ahead forecasts. Code provided in Appendix \ref{appendix2} makes the application of all discussed methods reproducible for users.