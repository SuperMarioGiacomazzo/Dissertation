\chapter{CONCLUSION}
The overall focus of this dissertation has been on the application and evaluation of Bayesian regularization and model selection methods to obtain sparse estimation of linear and nonlinear time series models. A different model and application is provided in each chapter to illustrate the overall efficacy of considering Bayesian approaches for discovering the relevant temporal dynamics for the purpose of forecasting at multi-step horizons. Each chapter provides a novelty that contributes to the growing field of Bayesian time series analysis. 

In Chapter \ref{chap:temp}, we utilized different shrinkage priors to estimate a 2-regime smooth transition autoregressive model with a more flexible parametric representation than previously used. The use of the \textit{dirichlet} prior to select the delay parameter allows for composite transition variables to be estimated. Regime-specific tuning parameters in hierachical representations of global-local shrinkage priors ensure that regularization is regime-specific. The corresponding Appendix \ref{appendix1} contains detailed \textbf{R} code making these methods reproducible for future applications. Using deviations from daily maximum water temperature profiles, we illustrate the ease of these methods in estimating smooth transition autoregressions with endogenous and exogenous lag effects. We often see smooth transition autoregressive models applied to univariate time series, but the Bayesian methods we discuss are able to perform selection on lag effects for input time series, such as deviations from maximum air temperature profiles.

The threshold autoregressive process is the limit of its smooth counterpart where the slope in the transition function approaches infinity. Often times in practice, the difficulty in estimation restricts consideration to threshold autoregressive models with at most 3 regimes. In Chapter \ref{chap:traffic},  we restructure the nonlinear threshold autoregressive process to a high dimensional linear regression model by only considering a finite set of thresholds. This re-framed approach is only found in a handful of works but should become industry standard since the linear form nests all threshold autoregressive models with regimes less than the sample size. In this context, we present a fully Bayesian three step model building procedure to not only select the number of regimes but also perform within regime variable selection. Empirical results from a high dimensional simulation study in Appendix \ref{appendix3} are referenced to defend the choice of the horseshoe+ shrinkage prior. Using traffic occupancy data, we demonstrate the effectiveness of these methods in identifying the best subset TAR model that often outperforms seasonal profiles for 3 minute, 9 minute, and 15 minute forecasting horizons. We also use final TAR models to produce density forecasts for the entire out-of-sample period. 

Chapter 4 focuses on subset selection of the classic autoregressive moving average model which has proven to be most popular in modeling and forecasting stationary time series. By considering subset selection methods, we are able to also estimate its multiplicative seasonal counterpart. From a frequentist viewpoint, penalized adaptive lasso estimation has been used to yield consistent subset selection of these models. We naturally extend to consider adaptive elastic net with a more flexible penalty. Previous works have used information criteria to select tuning parameters in these circumstances. Various cross-validation techniques are also appropriate alternatives to information criteria, even for time series data. For comparison, we also look at a Bayesian approach that uses the Kullback-Leibler distance to identify the best submodel that obtains a posterior predictive distribution relatively close to the predictions from the full model. Within this method, we examine multiple ways to identify the final model that do not require cross-validation. In simulation, we demonstrate potential pitfalls of adaptive lasso and adaptive elastic net on estimation of autoregressive moving average models, and highlight the advantages of the Bayesian-based posterior predictive projection algorithm. Applying these methods to $\textrm{CO}_2$ data from two locations, we evaluate the differences in model selection from a library of subset estimation techniques. Multiple measures of forecasting accuracy and bias assess the techniques for one-step ahead forecasts. Code provided in Appendix \ref{appendix2} makes the application of all discussed methods reproducible for users.